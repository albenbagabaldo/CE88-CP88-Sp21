{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clustering Census Data\n",
    "**NOTE**: parts of this notebook have been\n",
    "borrowed from [GDS'17 - Lab\n",
    "6](http://darribas.org/gds17/content/labs/lab_06.html)\n",
    "--> and its Texbook Source is: [Geographic Data Science with Python](https://geographicdata.science/book/notebooks/10_clustering_and_regionalization.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: esda in /Users/alben/opt/anaconda3/lib/python3.7/site-packages (2.3.6)\n",
      "Requirement already satisfied: scikit-learn in /Users/alben/opt/anaconda3/lib/python3.7/site-packages (from esda) (0.22.1)\n",
      "Requirement already satisfied: libpysal in /Users/alben/opt/anaconda3/lib/python3.7/site-packages (from esda) (4.4.0)\n",
      "Requirement already satisfied: scipy>=0.11 in /Users/alben/opt/anaconda3/lib/python3.7/site-packages (from esda) (1.4.1)\n",
      "Requirement already satisfied: pandas in /Users/alben/opt/anaconda3/lib/python3.7/site-packages (from esda) (1.2.2)\n",
      "Requirement already satisfied: numpy>=1.11.0 in /Users/alben/opt/anaconda3/lib/python3.7/site-packages (from scikit-learn->esda) (1.20.1)\n",
      "Requirement already satisfied: joblib>=0.11 in /Users/alben/opt/anaconda3/lib/python3.7/site-packages (from scikit-learn->esda) (0.14.1)\n",
      "Requirement already satisfied: requests in /Users/alben/opt/anaconda3/lib/python3.7/site-packages (from libpysal->esda) (2.25.1)\n",
      "Requirement already satisfied: beautifulsoup4 in /Users/alben/opt/anaconda3/lib/python3.7/site-packages (from libpysal->esda) (4.8.2)\n",
      "Requirement already satisfied: jinja2 in /Users/alben/opt/anaconda3/lib/python3.7/site-packages (from libpysal->esda) (2.11.1)\n",
      "Requirement already satisfied: pytz>=2017.3 in /Users/alben/opt/anaconda3/lib/python3.7/site-packages (from pandas->esda) (2019.3)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in /Users/alben/opt/anaconda3/lib/python3.7/site-packages (from pandas->esda) (2.8.1)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /Users/alben/opt/anaconda3/lib/python3.7/site-packages (from requests->libpysal->esda) (2.8)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/alben/opt/anaconda3/lib/python3.7/site-packages (from requests->libpysal->esda) (2019.11.28)\n",
      "Requirement already satisfied: chardet<5,>=3.0.2 in /Users/alben/opt/anaconda3/lib/python3.7/site-packages (from requests->libpysal->esda) (3.0.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /Users/alben/opt/anaconda3/lib/python3.7/site-packages (from requests->libpysal->esda) (1.25.8)\n",
      "Requirement already satisfied: soupsieve>=1.2 in /Users/alben/opt/anaconda3/lib/python3.7/site-packages (from beautifulsoup4->libpysal->esda) (1.9.5)\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in /Users/alben/opt/anaconda3/lib/python3.7/site-packages (from jinja2->libpysal->esda) (1.1.1)\n",
      "Requirement already satisfied: six>=1.5 in /Users/alben/opt/anaconda3/lib/python3.7/site-packages (from python-dateutil>=2.7.3->pandas->esda) (1.14.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install esda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from esda.moran import Moran\n",
    "import libpysal.weights.set_operations as Wsets\n",
    "from libpysal.weights import Queen, KNN\n",
    "import seaborn \n",
    "import pandas\n",
    "import geopandas \n",
    "import numpy\n",
    "from sklearn.cluster import KMeans, AgglomerativeClustering\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "\n",
    "Clustering is a method of data analysis that draws insights\n",
    "from large, complex multivariate processes.\n",
    "\n",
    "It works by finding similarities among the many dimensions in a multivariate process, condensing them down into a simpler representation.\n",
    "\n",
    "Thus, through clustering, we seek to reduce the complexity of the data\n",
    "\n",
    "Often, clustering involves sorting observations into groups. For these groups to be\n",
    "meaningful, members of a group should be more similar to one another than they are \n",
    "to members of a different group.\n",
    "\n",
    "Each group is referred to as a *cluster* while the process of assigning\n",
    "objects to groups is known as *clustering*. \n",
    "\n",
    "\n",
    "Since a good cluster is more\n",
    "similar internally than it is to any other cluster, these cluster-level profiles\n",
    "provide a convenient shorthand to describe the original complex multivariate process.\n",
    "\n",
    "Observations in one group may have consistently high \n",
    "scores on some traits but low scores on others. \n",
    "The analyst only needs to look at the profile of a cluster in order to get a\n",
    "good sense of what all the observations in that cluster are like, instead of\n",
    "having to consider all of the complexities of the original multivariate process at once. \n",
    "Throughout data science, and particularly in geographic data science, \n",
    "clustering is widely used to provide insights on the\n",
    "geographic structure of complex multivariate spatial data. \n",
    "\n",
    " \n",
    "\n",
    "We then consider geodemographic approaches to clustering&mdash;the application\n",
    "of multivariate clustering to spatially referenced demographic data.\n",
    "Two popular clustering algorithms are employed: k-means method.\n",
    "Mapping the spatial distribution of the resulting clusters \n",
    "reveals interesting insights on the socioeconomic structure of the San Diego\n",
    "metropolitan area. We also see that in many cases, clusters are spatially \n",
    "fragmented. That is, a cluster may actually consist of different areas that are not\n",
    "spatially connected. Indeed, some clusters will have their members strewn all over the map. \n",
    "This will illustrate why connectivity might be important when building insight\n",
    "about spatial data, since these clusters will not at all provide intelligible regions. \n",
    "So, we then will move on to regionalization, exploring different approaches that\n",
    "incorporate geographical constraints into the exploration of the social structure of San Diego.\n",
    "\n",
    "## Data\n",
    "\n",
    "The dataset we will use in this chapter comes from the American Community Survey\n",
    "(ACS). In particular, we examine data at the Census Tract level in San Diego,\n",
    "California in 2017. Let us begin by reading in the data as a GeoDataFrame and\n",
    "exploring the attribute names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read file\n",
    "db = geopandas.read_file('sandiego_tracts.gpkg')\n",
    "# Print column names\n",
    "db.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "db.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To make things easier later on, let us collect the variables we will use to\n",
    "characterize Census tracts. These variables capture different aspects of the socio-\n",
    "economic reality of each area and, taken together, they provide a comprehensive\n",
    "characterization of San Diego as a whole:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_variables =  [\n",
    "    'median_house_value', # Median house value\n",
    "    'pct_white',          # Percent of tract population that is white\n",
    "    'pct_rented',         # Percent of households that are rented\n",
    "    'pct_hh_female',      # Percent of female-led households \n",
    "    'pct_bachelor',       # Percent of tract population with a Bachelors degree\n",
    "    'median_no_rooms',    # Median number of rooms in the tract's households\n",
    "    'income_gini',        # Gini index measuring tract wealth inequality\n",
    "    'median_age',         # Median age of tract population\n",
    "    'tt_work'             # Travel time to work \n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exploring the data\n",
    "\n",
    "Now let's start building up our understanding of this\n",
    "dataset through both visual and summary statistical measures.\n",
    "\n",
    "We will start by\n",
    "looking at the spatial distribution of each variable alone.\n",
    "Let's use sequential color scheme for the nine attributes and compare these choropleth maps side-by-side:\n",
    "https://matplotlib.org/3.1.1/gallery/color/colormap_reference.html\n",
    "(Yellow and light means low Red and Dark means High and organge is in the middle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f, axs = plt.subplots(nrows=3, ncols=3, figsize=(12, 12))\n",
    "# Make the axes accessible with single indexing\n",
    "axs = axs.flatten()\n",
    "# Start a loop over all the variables of interest\n",
    "for i, col in enumerate(cluster_variables):\n",
    "    # select the axis where the map will go\n",
    "    ax = axs[i]\n",
    "    # Plot the map\n",
    "    db.plot(column=col, ax=ax, scheme='Quantiles', \n",
    "            linewidth=0, cmap='YlOrRd')\n",
    "    # Remove axis clutter\n",
    "    ax.set_axis_off()\n",
    "    # Set the axis title to the name of variable being plotted\n",
    "    ax.set_title(col)\n",
    "# Display the figure\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Many visual patterns jump out from the maps, revealing both commonalities as\n",
    "well as differences across the spatial distributions of the individual variables.\n",
    "Several variables tend to increase in value from the east to the west\n",
    "(`pct_rented`, `median_house_value`, `median_no_rooms`, and `tt_work`) while others\n",
    "\n",
    "Some have a spatial trend in the opposite direction (`pct_rented`, `median_no_rooms`).\n",
    "\n",
    "If all variables display very similar \n",
    "spatial patterns, the amount of useful information across the maps is \n",
    "actually smaller than it appears, so cluster profiles may be much less useful as well.\n",
    "\n",
    "It is also important to consider whether the variables display any\n",
    "spatial autocorrelation, as this will affect the spatial structure of the\n",
    "resulting clusters. \n",
    "\n",
    "\n",
    "First, we need to build a spatial weights matrix that encodes the spatial\n",
    "relationships in our San Diego data. We will start with queen contiguity:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w = Queen.from_dataframe(db)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we have seen before, `w` does not contain any islands:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w.islands"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's calculate Moran's I for the variables being used. This will measure\n",
    "the extent to which each variable contains spatial structure:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set seed for reproducibility\n",
    "numpy.random.seed(123456)\n",
    "# Calculate Moran's I for each variable\n",
    "mi_results = [Moran(db[variable], w) for variable in cluster_variables]\n",
    "# Display on table\n",
    "table = pandas.DataFrame([(variable, res.I, res.p_sim) \\\n",
    "                          for variable,res \\\n",
    "                          in zip(cluster_variables, mi_results)\n",
    "                         ], columns=['Variable', \"Moran's I\", 'P-value']\n",
    "                        )\\\n",
    "              .set_index('Variable')\n",
    "table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each of the variables displays significant positive spatial autocorrelation,\n",
    "that Tobler's law. This means we also should expect clusters to have\n",
    "spatial coherence in addition to the coherence in their profiles,\n",
    "since there is strong positive autocorrelation in all of the input variables.\n",
    "\n",
    "Let's  consider the\n",
    "spatial correlation between variables. Here, we will measure this using the\n",
    "bivariate correlation in the maps of covariates themselves.\n",
    "\n",
    "Given the 9 maps, there are 36 pairs of maps that must be compared. This is too \n",
    "many maps to process visually, so we can turn to an alternative tool to\n",
    "explicitly focus on the bivariate relations between each pair of attributes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max(db['median_house_value'])   #Tract with Max Median House Value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "min(db['median_house_value'])   #Tract with Min Median House Value Median House Value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum(db['median_house_value'])/len(db['median_house_value']) #Average of Median House Value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum(db['tt_work'])/len(db['tt_work'])/60 #averate tt_work"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max(db['tt_work'])/60   #max TT work is Six Hours!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = seaborn.pairplot(db[cluster_variables], kind='reg', diag_kind='kde')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Two different types of plots are contained in the scatterplot matrix. On the\n",
    "diagonal are the density functions for the nine attributes. These allow for an\n",
    "inspection of the overall morphology of the attribute's value distribution.\n",
    "Examining these we see that our selection of variables includes those that are\n",
    "negatively skewed (`pct_white` and `pct_hh_female`) as well as positively skewed\n",
    "(`median_house_value`, `pct_bachelor`, and `tt_work`).\n",
    "\n",
    "The second type of visualization lies in the off-diagonal cells of the matrix; \n",
    "these are bi-variate scatterplots. Each cell shows the association between one\n",
    "pair of variables. Several of these cells indicate positive linear\n",
    "associations (`median_age` Vs. `median_house_value`, `median_house_value` Vs. `median_no_rooms`)\n",
    "while other cells display negative correlation (`median_house_value` Vs. `pct_rented`,\n",
    "`median_no_rooms` Vs. `pct_rented`, and `median_age` Vs. `pct_rented`). The one variable\n",
    "that tends to have consistenty weak association with the other variables is\n",
    "`tt_work`, and in part this appears to reflect its rather concentrated \n",
    "distribution as seen on the lower right diagonal corner cell.\n",
    "\n",
    "## Geodemographic Clusters in San Diego Census Tracts\n",
    "\n",
    "We now will move\n",
    "beyond the implicitly bi-variate focus to consider the full multidimensional\n",
    "nature of this data set. \n",
    "\n",
    "Altogether, these methods use\n",
    "multivariate clustering algorithms to construct a known number of\n",
    "clusters ($k$), where the number of clusters is typically smaller than the \n",
    "number of observations to be clustered. \n",
    "\n",
    "Each cluster is given a unique label,\n",
    "and these labels are mapped. Using the clusters' profile and label, the map of \n",
    "labels can be interpreted to get a sense of the spatial distribution of \n",
    "sociodemographic traits. The power of clustering comes\n",
    "from taking statistical variation across several dimensions and compressing it\n",
    "into a single categorical one that we can visualize through a map. To\n",
    "demonstrate the variety of approaches in clustering, we will show a popular\n",
    "clustering algorithms: k-means.\n",
    "\n",
    "### K-means\n",
    "\n",
    "K-means is probably the most widely used approach to\n",
    "cluster a dataset. The algorithm groups observations into a\n",
    "prespecified number of clusters so that that each observation is\n",
    "closer to the mean of its own cluster than it is to the mean of any other cluster.\n",
    "\n",
    "The k-means problem is solved by iterating between an assignment step and an update step. \n",
    "First, all observations are randomly assigned one of the $k$ labels. \n",
    "\n",
    "Next, the multivariate mean over all covariates is calculated for each of the clusters.\n",
    "Then, each observation is reassigned to the cluster with the closest mean. \n",
    "\n",
    "If the observation is already assigned to the cluster whose mean it is closest to,\n",
    "the observation remains in that cluster. This assignment-update process continues\n",
    "until no further reassignments are necessary.\n",
    "\n",
    "The nature of this algorithm requires us to select the number of clusters we \n",
    "want to create. The right number of clusters is unknown in practice. For\n",
    "illustration, we will use $k=5$ in the `KMeans` implementation from\n",
    "`scikit-learn`. To proceed, we first create a `KMeans` clusterer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialise KMeans instance\n",
    "kmeans = KMeans(n_clusters=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we call the `fit` method to actually apply the k-means algorithm to our data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the seed for reproducibility\n",
    "numpy.random.seed(1234)\n",
    "# Run K-Means algorithm\n",
    "k5cls = kmeans.fit(db[cluster_variables])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that the clusters have been assigned, we can examine the label vector, which \n",
    "records the cluster to which each observation is assigned:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k5cls.labels_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The integer labels should be viewed as denoting membership only &mdash;\n",
    "the numerical differences between the values for the labels are meaningless.\n",
    "The profiles of the various clusters must be further explored by looking\n",
    "at the values of each dimension. \n",
    "\n",
    "But, before we do that, let's make a map.\n",
    "\n",
    "### Spatial Distribution of Clusters\n",
    "\n",
    "Having obtained the cluster labels, we can display the spatial\n",
    "distribution of the clusters by using the labels as the categories in a\n",
    "choropleth map. This allows us to quickly grasp any sort of spatial pattern the \n",
    "clusters might have. Since clusters represent areas with similar\n",
    "characteristics, mapping their labels allows to see to what extent similar areas tend\n",
    "to have similar locations.\n",
    "Thus, this gives us one map that incorporates the information of from all nine covariates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assign labels into a column\n",
    "db['k5cls'] = k5cls.labels_\n",
    "# Setup figure and ax\n",
    "f, ax = plt.subplots(1, figsize=(9, 9))\n",
    "# Plot unique values choropleth including a legend and with no boundary lines\n",
    "db.plot(column='k5cls', categorical=True, legend=True, linewidth=0, ax=ax)\n",
    "# Remove axis\n",
    "ax.set_axis_off()\n",
    "# Keep axes proportionate\n",
    "plt.axis('equal')\n",
    "# Add title\n",
    "plt.title(r'Geodemographic Clusters (k-means, $k=5$)')\n",
    "# Display the map\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that a set of tracts with the same color emerge.\n",
    "\n",
    "Our eyes are drawn to the larger polygons in the eastern part of the\n",
    "county, giving the impression that cluster 2 is the dominant cluster. While this\n",
    "seems to be true in terms of land area (and we will verify this below).\n",
    "\n",
    "### Statistical Analysis of the Cluster Map\n",
    "\n",
    "To complement the geovisualization of the clusters, we can explore the\n",
    "statistical properties of the cluster map. This process allows us to delve\n",
    "into what observations are part of each cluster and what their\n",
    "characteristics are.\n",
    "\n",
    "This gives us the profile of each cluster so we can interpret the meaning of the\n",
    "labels we've obtained. We can start, for example, by\n",
    "considering cardinality, or the count of observations in each cluster:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group data table by cluster label and count observations\n",
    "k5sizes = db.groupby('k5cls').size()\n",
    "k5sizes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And we can get a visual representation of cardinality as well:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = k5sizes.plot.bar()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are substantial differences in the sizes of the five clusters, with two very\n",
    "large clusters (0, 3), one medium sized cluster (2), and two small clusters (1,\n",
    "4). Cluster 3 is the largest when measured by the number of assigned tracts.\n",
    "This confirms our intuition from the map above, where we got the visual impression\n",
    "that tracts in cluster 3 seemed to have the largest area. Let's see if this is \n",
    "the case. To do so we can use the `dissolve` operation in `geopandas`, which \n",
    "combines all tracts belonging to each cluster into a single\n",
    "polygon object. After we have dissolved all the members of the clusters,\n",
    "we report the total land area of the cluster:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dissolve areas by Cluster, aggregate by summing, and keep column for area\n",
    "areas = db.dissolve(by='k5cls', aggfunc='sum')['area_sqm']\n",
    "areas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And, to show this visually:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "areas.plot.bar()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our visual impression is confirmed: cluster 2 contains tracts that\n",
    "together comprise 6,636 square kilometers (approximately 2562 square miles),\n",
    "which accounts for over half of the total land area in the county:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "areas[2]/areas.sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's move on to build the profiles for each cluster. Again, the profiles is what\n",
    "provides the conceptual shorthand, moving from the arbitrary label to a meaningful\n",
    "collection of observations with similar attributes. To build a basic profile, we can\n",
    "compute the means of each of the attributes in every cluster:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group table by cluster label, keep the variables used \n",
    "# for clustering, and obtain their mean\n",
    "k5means = db.groupby('k5cls')[cluster_variables].mean()\n",
    "k5means.T.round(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that cluster 4, for example, is composed of tracts that have\n",
    "the highest average `median_house_value`, and also the highest level of inequality\n",
    "(`income_gini`); and cluster 4 contains an older population (`median_age`)\n",
    "who tend to live in housing units with more rooms (`median_no_rooms`).\n",
    "Average values, however, can hide a great deal of detail and, in some cases,\n",
    "give wrong impressions about the type of data distribution they represent. To\n",
    "obtain more detailed profiles, we can use the `describe` command in `pandas`, \n",
    "after grouping our observations by their clusters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group table by cluster label, keep the variables used \n",
    "# for clustering, and obtain their descriptive summary\n",
    "k5desc = db.groupby('k5cls')[cluster_variables].describe()\n",
    "# Loop over each cluster and print a table with descriptives\n",
    "for cluster in k5desc.T:\n",
    "    print('\\n\\t---------\\n\\tCluster %i'%cluster)\n",
    "    print(k5desc.T[cluster].unstack())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However, this approach quickly gets out of hand: more detailed profiles can simply\n",
    "return to an unwieldy mess of numbers. A better approach to constructing\n",
    "cluster profiles is be to draw the distributions of cluster members' data.\n",
    "To do this we need to \"tidy up\" the dataset. A tidy dataset ([Wickham,\n",
    "2014](https://www.jstatsoft.org/article/view/v059i10)) is one where every row is\n",
    "an observation, and every column is a variable. Thus, a few steps are required \n",
    "to tidy up our labelled data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Index db on cluster ID\n",
    "tidy_db = db.set_index('k5cls')\n",
    "# Keep only variables used for clustering\n",
    "tidy_db = tidy_db[cluster_variables]\n",
    "# Stack column names into a column, obtaining \n",
    "# a \"long\" version of the dataset\n",
    "tidy_db = tidy_db.stack()\n",
    "# Take indices into proper columns\n",
    "tidy_db = tidy_db.reset_index()\n",
    "# Rename column names\n",
    "tidy_db = tidy_db.rename(columns={\n",
    "                        'level_1': 'Attribute', \n",
    "                        0: 'Values'})\n",
    "# Check out result\n",
    "tidy_db.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(tidy_db)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we are ready to plot. Below, we'll show the distribution of each cluster's values\n",
    "for each variable. This gives us the full distributional profile of each cluster:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup the facets\n",
    "facets = seaborn.FacetGrid(data=tidy_db, col='Attribute', hue='k5cls', \\\n",
    "                  sharey=False, sharex=False, aspect=2, col_wrap=3)\n",
    "# Build the plot from `sns.kdeplot`\n",
    "_ = facets.map(seaborn.kdeplot, 'Values', shade=True).add_legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This allows us to see that, while some attributes such as the percentage of\n",
    "female households (`pct_hh_female`) display largely the same distribution for\n",
    "each cluster, others paint a much more divided picture (e.g. `median_house_value`).\n",
    "Taken altogether, these graphs allow us to start delving into the multidimensional \n",
    "complexity of each cluster and the types of areas behind them.\n",
    "\n",
    "## Clustering Algorithms\n",
    "k-means is only one clustering algorithm. There are\n",
    "plenty more. Agglomerative clustering works by building a hierarchy of\n",
    "clustering solutions that starts with all singletons (each observation is a single\n",
    "cluster in itself) and ends with all observations assigned to the same cluster.\n",
    "These extremes are not very useful in themselves. But, in between, the hierarchy\n",
    "contains many distinct clustering solutions with varying levels of detail. \n",
    "The intuition behind the algorithm is also rather straightforward: \n",
    "\n",
    "1) begin with everyone as part of its own cluster; \n",
    "2) find the two closest observations based on a distance metric (e.g. euclidean); \n",
    "3) join them into a new cluster; \n",
    "4) repeat steps 2) and 3) until reaching the degree of aggregation desired. \n",
    "\n",
    "The algorithm is thus called \"agglomerative\"\n",
    "because it starts with individual clusters and \"agglomerates\" them into fewer\n",
    "and fewer clusters containing more and more observations each. Also, like with \n",
    "k-means, AHC does require the user to specify a number of clusters in advance.\n",
    "This is because, following from the mechanism the method has to build clusters, \n",
    "AHC can provide a solution with as many clusters as observations ($k=n$),\n",
    "or with a only one ($k=1$).\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set seed for reproducibility\n",
    "numpy.random.seed(0)\n",
    "# Iniciate the algorithm\n",
    "model = AgglomerativeClustering(linkage='ward', n_clusters=5)\n",
    "# Run clustering\n",
    "model.fit(db[cluster_variables])\n",
    "# Assign labels to main data table\n",
    "db['ward5'] =model.labels_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As above, we can check the number of observations that fall within each cluster:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ward5sizes = db.groupby('ward5').size()\n",
    "ward5sizes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Further, we can check the simple average profiles of our clusters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ward5means = db.groupby('ward5')[cluster_variables].mean()\n",
    "ward5means.T.round(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And again, we can create a plot of the profiles' distributions (after properly \n",
    "tidying up):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Index db on cluster ID\n",
    "tidy_db = db.set_index('ward5')\n",
    "# Keep only variables used for clustering\n",
    "tidy_db = tidy_db[cluster_variables]\n",
    "# Stack column names into a column, obtaining \n",
    "# a \"long\" version of the dataset\n",
    "tidy_db = tidy_db.stack()\n",
    "# Take indices into proper columns\n",
    "tidy_db = tidy_db.reset_index()\n",
    "# Rename column names\n",
    "tidy_db = tidy_db.rename(columns={\n",
    "                        'level_1': 'Attribute', \n",
    "                        0: 'Values'})\n",
    "# Check out result\n",
    "tidy_db.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup the facets\n",
    "facets = seaborn.FacetGrid(data=tidy_db, col='Attribute', hue='ward5', \\\n",
    "                  sharey=False, sharex=False, aspect=2, col_wrap=3)\n",
    "# Build the plot as a `sns.kdeplot`\n",
    "_ = facets.map(seaborn.kdeplot, 'Values', shade=True).add_legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the sake of brevity, we will not spend much time on the plots above.\n",
    "However, the interpretation is analogous to that of the k-means example.\n",
    "\n",
    "On the spatial side, we can explore the geographical dimension of the\n",
    "clustering solution by making a map the clusters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "db['ward5'] =model.labels_\n",
    "# Setup figure and ax\n",
    "f, ax = plt.subplots(1, figsize=(9, 9))\n",
    "# Plot unique values choropleth including a legend and with no boundary lines\n",
    "db.plot(column='ward5', categorical=True, legend=True, linewidth=0, ax=ax)\n",
    "# Remove axis\n",
    "ax.set_axis_off()\n",
    "# Keep axes proportionate\n",
    "plt.axis('equal')\n",
    "# Add title\n",
    "plt.title('Geodemographic Clusters (AHC, $k=5$)')\n",
    "# Display the map\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And, to make comparisons simpler, we can display both the k-means and the AHC\n",
    "results side by side:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "db['ward5'] =model.labels_\n",
    "# Setup figure and ax\n",
    "f, axs = plt.subplots(1, 2, figsize=(12, 6))\n",
    "\n",
    "ax = axs[0]\n",
    "# Plot unique values choropleth including a legend and with no boundary lines\n",
    "db.plot(column='ward5', categorical=True, cmap='Set2', \n",
    "        legend=True, linewidth=0, ax=ax)\n",
    "# Remove axis\n",
    "ax.set_axis_off()\n",
    "# Keep axes proportionate\n",
    "ax.axis('equal')\n",
    "# Add title\n",
    "ax.set_title('K-Means solution ($k=5$)')\n",
    "\n",
    "ax = axs[1]\n",
    "# Plot unique values choropleth including a legend and with no boundary lines\n",
    "db.plot(column='k5cls', categorical=True, cmap='Set3',\n",
    "        legend=True, linewidth=0, ax=ax)\n",
    "# Remove axis\n",
    "ax.set_axis_off()\n",
    "# Keep axes proportionate\n",
    "ax.axis('equal')\n",
    "# Add title\n",
    "ax.set_title('AHC solution ($k=5$)')\n",
    "\n",
    "# Display the map\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While we must remember our earlier caveat about how irregular polygons can \n",
    "baffle our visual intuition, a closer visual inspection of the cluster geography\n",
    "suggests a clear pattern: although they are not identical, both clusterings capture\n",
    "very similar overall spatial structure. Furthermore, both solutions slightly violate \n",
    "Tobler's law, since all of the clusters have disconnected components. The five\n",
    "multivariate clusters in each case are actually composed of many disparate \n",
    "geographical areas, strewn around the map according only to the structure of the\n",
    "data and not its geography. That is, in order to travel to\n",
    "every tract belonging to a cluster, we would have to journey through\n",
    "other clusters as well."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Even though we have specified a spatial constraint, the constraint applies to the\n",
    "connectivity graph modeled by our weights matrix. Therefore, using k-nearest neighbors\n",
    "to constrain the agglomerative clustering may not result in regions that are connected\n",
    "according to a different connectivity rule, such as the queen contiguity rule used\n",
    "in the previous section. However, the regionalization here is fortuitous; even though\n",
    "we used the 4-nearest tracts to constrain connectivity, all but one of the clusters, \n",
    "cluster 4, is *also* connected according to our earlier queen contiguity rule. \n",
    "\n",
    "At first glance, this may seem counter-intuitive. We did specify the spatial\n",
    "constraint, so our initial reaction is that the connectivity constraint is\n",
    "violated. However, this is not the case, since the constraint applies to the\n",
    "k-nearest neighbor graph, not the queen contiguity graph. Therefore, since tracts\n",
    "in this solution are considered as connected to their four closest neighbors,\n",
    "clusters can \"leapfrog\" over one another. Thus, it is important to recognize that\n",
    "the apparent spatial structure of regionalizations will depend on how the \n",
    "connectivity of observations is modeled. \n",
    "\n",
    "## Conclusion\n",
    "\n",
    "Thus, clustering reduces this complexity into a single conceptual shorthand by which \n",
    "people can easily describe complex and multifaceted data. \n",
    "Clustering constructs groups of observations (called *clusters*)\n",
    "with coherent *profiles*, or distinct and internally-consistent \n",
    "distributional/descriptive characteristics. \n",
    "These profiles are the conceptual shorthand, since members of each cluster should\n",
    "be more similar to the cluster at large than they are to any other cluster. \n",
    "Many different clustering methods exist; they differ on how the \"cluster at large\" \n",
    "is defined, and how \"similar\" members must be to clusters, or how these clusters\n",
    "are obtained."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Note next class we see how to select K and "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "jupytext": {
   "formats": "ipynb,md"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
